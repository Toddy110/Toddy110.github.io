{"meta":{"title":"Modesty.","subtitle":"Stay hungry, stay foolish","description":"","author":"ToddyN","url":"https://toddy110.github.io","root":"/"},"pages":[{"title":"404","date":"2025-09-19T06:04:56.000Z","updated":"2025-09-19T06:05:57.189Z","comments":true,"path":"404/index.html","permalink":"https://toddy110.github.io/404/index.html","excerpt":"","text":""},{"title":"About","date":"2025-10-10T09:30:55.703Z","updated":"2025-10-10T09:30:55.703Z","comments":false,"path":"about/index.html","permalink":"https://toddy110.github.io/about/index.html","excerpt":"","text":"这里是我的个人简介页。 名称：ToddyN 职业：Student 格言：Stay hungry, stay foolish 如果你看到这里，说明 About 页面已经配置成功啦。"},{"title":"contact","date":"2025-09-19T06:47:51.000Z","updated":"2025-09-19T06:59:00.984Z","comments":true,"path":"contact/index.html","permalink":"https://toddy110.github.io/contact/index.html","excerpt":"","text":"欢迎来到我的留言板！ 在这里，您可以： 💬 留下您的想法和建议 🤝 申请友情链接 📧 与我交流技术问题 💡 分享有趣的想法 请在下方评论区留言，我会尽快回复！"},{"title":"friends","date":"2025-10-10T04:00:00.000Z","updated":"2025-10-10T08:53:28.659Z","comments":true,"path":"friends/index.html","permalink":"https://toddy110.github.io/friends/index.html","excerpt":"","text":"欢迎来到友情链接页，这里展示一些我推荐的站点"},{"title":"categories","date":"2025-09-08T01:00:42.000Z","updated":"2025-09-08T01:01:33.000Z","comments":true,"path":"categories/index.html","permalink":"https://toddy110.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-09-08T01:05:16.000Z","updated":"2025-09-08T01:06:40.000Z","comments":true,"path":"tags/index.html","permalink":"https://toddy110.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MNIST 多层感知机（MLP）分类器代码详解","slug":"MNIST-多层感知机（MLP）分类器代码详解","date":"2025-10-13T07:17:23.000Z","updated":"2025-10-13T07:19:11.056Z","comments":true,"path":"2025/10/13/MNIST-多层感知机（MLP）分类器代码详解/","permalink":"https://toddy110.github.io/2025/10/13/MNIST-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%EF%BC%88MLP%EF%BC%89%E5%88%86%E7%B1%BB%E5%99%A8%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"本项目实现了一个基于 PyTorch 的多层感知机（MLP）模型，用于对 MNIST 手写数字图片进行分类。本文将对 mnist_mlp_classifier.py 代码进行逐行详细解析，帮助初学者理解每一步的设计思路、参数设置原因，以及涉及到的 PyTorch 和 torchvision 库函数的用法。 1. 数据预处理与加载1.1 导入相关库import torch from torchvision import transforms, datasets from torch.utils.data import DataLoader import torch.nn.functional as F import torch.optim as optim torch：PyTorch 的核心库，包含张量、自动求导、神经网络等模块。 torchvision.transforms：常用的数据预处理方法集合。 torchvision.datasets：常用数据集的下载与加载接口。 torch.utils.data.DataLoader：用于批量加载数据，支持多线程和数据打乱。 torch.nn.functional：包含常用的无状态神经网络函数（如激活函数 ReLU）。 torch.optim：优化器模块，包含 SGD、Adam 等。 1.2 批量大小设置batch_size = 64 为什么设置为64？ 批量大小（batch size）是深度学习训练中的重要超参数。较小的 batch size（如32、64）可以加快模型收敛速度，提升泛化能力，同时不会占用过多内存。64 是常用的折中选择。 1.3 数据预处理操作transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) transforms.Compose：将多个预处理操作串联起来。 transforms.ToTensor()：将 PIL 图片或 numpy 数组转为 PyTorch 的 FloatTensor，并自动归一化到 [0,1]。 transforms.Normalize((0.1307,), (0.3081,))：对每个像素做标准化，(x-mean)/std，其中 mean=0.1307，std=0.3081 是 MNIST 全体像素的统计值。 为什么要标准化？ 标准化可以加快模型收敛速度，提升训练稳定性。 1.4 加载数据集train_dataset = datasets.MNIST( root='D:/PythonCode/Pytorch_learning/MNIST', train=True, download=True, transform=transform ) root：数据集存放路径。 train=True：加载训练集。 download=True：本地没有数据时自动下载。 transform：应用上面定义的预处理。 同理，测试集： test_dataset = datasets.MNIST( root='D:/PythonCode/Pytorch_learning/MNIST', train=False, download=True, transform=transform ) 1.5 构建数据加载器train_loader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True ) test_loader = DataLoader( test_dataset, batch_size=batch_size, shuffle=False ) DataLoader：将数据集分批次加载，支持多线程和数据打乱。 shuffle=True：训练集每个 epoch 前打乱，提升泛化能力。 shuffle=False：测试集不打乱，保证评估一致性。 2. 神经网络结构定义2.1 定义多层感知机（MLP）class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.l1 = torch.nn.Linear(784, 512) self.l2 = torch.nn.Linear(512, 256) self.l3 = torch.nn.Linear(256, 128) self.l4 = torch.nn.Linear(128, 64) self.l5 = torch.nn.Linear(64, 10) def forward(self, x): x = x.view(-1, 784) x = F.relu(self.l1(x)) x = F.relu(self.l2(x)) x = F.relu(self.l3(x)) x = F.relu(self.l4(x)) x = self.l5(x) return x 继承自 torch.nn.Module，这是所有神经网络模块的基类。 __init__ 方法中定义了5个全连接层（Linear）： self.l1 = torch.nn.Linear(784, 512)：输入层，28x28=784个像素，输出512个特征。 self.l2 = torch.nn.Linear(512, 256)：第1隐藏层。 self.l3 = torch.nn.Linear(256, 128)：第2隐藏层。 self.l4 = torch.nn.Linear(128, 64)：第3隐藏层。 self.l5 = torch.nn.Linear(64, 10)：输出层，10个类别。 forward 方法定义前向传播： x.view(-1, 784)：将输入图片展平成一维向量。 每层后接 ReLU 激活函数（F.relu），输出层不加激活，直接输出 logits。 参数设置理由 多层结构（深度）有助于模型学习更复杂的特征。 隐藏层神经元数量逐层递减，有助于特征压缩和泛化。 输出层为10，对应数字0-9。 3. 损失函数与优化器3.1 损失函数criterion = torch.nn.CrossEntropyLoss() CrossEntropyLoss：适用于多分类任务，自动将 logits 通过 softmax 归一化，并计算交叉熵损失。 3.2 优化器optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) optim.SGD：随机梯度下降优化器。 model.parameters()：需要优化的参数。 lr=0.01：学习率，控制每次参数更新的步长。 momentum=0.5：动量项，有助于加速收敛，减少震荡。 参数设置理由 学习率0.01是常用的初始值，适合大多数场景。 动量0.5可以在一定程度上提升训练速度和稳定性。 4. 训练函数详解def train(epoch): running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0 train(epoch)：训练模型一个 epoch。 optimizer.zero_grad()：每次反向传播前清空梯度，防止梯度累加。 outputs = model(inputs)：前向传播，得到预测结果。 loss = criterion(outputs, target)：计算损失。 loss.backward()：反向传播，计算梯度。 optimizer.step()：更新参数。 running_loss：累计损失，每300个 batch 打印一次平均损失。 参数说明 epoch：当前训练轮数。 batch_idx：当前 batch 的编号。 5. 测试函数详解def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: images, labels = data outputs = model(images) _, predicted = torch.max(outputs.data, dim=1) total += labels.size(0) correct += (predicted == labels).sum().item() print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total)) torch.no_grad()：测试时不计算梯度，节省内存和加快速度。 torch.max(outputs.data, dim=1)：返回每行最大值和对应的索引，索引即为预测类别。 统计预测正确的样本数，计算准确率。 参数说明 outputs.data：模型输出的 logits。 dim=1：在类别维度上取最大值。 6. 主程序入口if __name__ == '__main__': for epoch in range(10): train(epoch) test() 训练和测试共进行10个 epoch。 每个 epoch 后在测试集上评估模型性能。 参数说明 range(10)：训练10轮。 7. 参数设置说明 batch_size=64：平衡训练速度和内存消耗。 学习率 lr=0.01：适合大多数场景的初始值。 momentum=0.5：加速收敛，减少震荡。 隐藏层神经元数：逐层递减，便于特征压缩和泛化。 epoch=10：适合初学者快速观察模型收敛情况。 8. PyTorch/torchvision 相关API详解 torch.nn.Module：所有神经网络模块的基类。 torch.nn.Linear(in_features, out_features)：全连接层。 torch.nn.functional.relu(x)：ReLU 激活函数。 torch.utils.data.DataLoader(dataset, batch_size, shuffle)：批量加载数据。 torchvision.datasets.MNIST：自动下载和加载 MNIST 数据集。 torchvision.transforms.Compose([...])：组合多个预处理操作。 torchvision.transforms.ToTensor()：图片转为张量。 torchvision.transforms.Normalize(mean, std)：标准化。 torch.optim.SGD(params, lr, momentum)：SGD 优化器。 torch.nn.CrossEntropyLoss()：交叉熵损失。 torch.no_grad()：上下文管理器，禁用梯度计算。 torch.max(input, dim)：返回最大值和索引。 小结本项目完整演示了用 PyTorch 实现多层感知机（MLP）进行 MNIST 手写数字识别的全过程，包括数据预处理、模型构建、训练与测试。结构清晰，注释详细，非常适合初学者学习和参考。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"RNN基础","slug":"RNN基础","date":"2025-10-13T07:12:09.000Z","updated":"2025-10-26T05:21:33.621Z","comments":true,"path":"2025/10/13/RNN基础/","permalink":"https://toddy110.github.io/2025/10/13/RNN%E5%9F%BA%E7%A1%80/","excerpt":"","text":"1. RNN基础概念1.1 什么是循环神经网络循环神经网络（Recurrent Neural Network, RNN）是一类专门处理序列数据的神经网络。与传统的全连接神经网络不同，RNN具有”记忆”能力，能够利用之前的信息来影响当前的输出。 核心特点： 序列处理：能够处理任意长度的序列数据 参数共享：在不同时间步使用相同的参数 记忆机制：通过隐藏状态保存历史信息 1.2 RNN的核心思想RNN的核心思想可以用一个简单的比喻来理解：就像人类阅读文章时，我们会记住前面读过的内容，然后结合当前读到的信息来理解整个句子。RNN也是这样，它在处理序列中的每个元素时，都会”记住”之前处理过的信息。 工作流程： 接收当前时间步的输入 结合上一个时间步的隐藏状态 计算当前时间步的输出和新的隐藏状态 将新的隐藏状态传递给下一个时间步 RNNCell展开示意图 图：RNN在时间维度上的展开示意图。展示了同一个RNN Cell如何在不同时间步被重复使用，通过隐藏状态 hth_tht​ 在时间步之间传递信息。 图片说明： 绿色矩形块：表示RNN Cell，在四个时间步中被重复使用（权重共享） 黄色圆形节点：表示输入 x1,x2,x3,x4x_1, x_2, x_3, x_4x1​,x2​,x3​,x4​，每个时间步的输入数据 蓝色圆形节点：表示隐藏状态 h0,h1,h2,h3,h4h_0, h_1, h_2, h_3, h_4h0​,h1​,h2​,h3​,h4​，包含历史信息 红色箭头：表示隐藏状态在时间步之间的传递，这是RNN的核心机制 黑色箭头：表示输入到RNN Cell和RNN Cell到输出的连接 这个图清楚地展示了RNN的循环特性：每个时间步的隐藏状态 hth_tht​ 不仅依赖于当前输入 xtx_txt​，还依赖于前一时间步的隐藏状态 ht−1h_{t-1}ht−1​，从而实现了对序列历史信息的记忆。 1.3 天气预测案例让我们用一个生动的天气预测例子来理解RNN： 假设我们要预测明天的天气，我们有以下数据： 今天：晴天 ☀️ 昨天：阴天 ☁️ 前天：雨天 🌧️ 大前天：晴天 ☀️ 传统方法可能只看今天的天气来预测明天，但RNN会考虑整个序列： 它”记住”了前几天的天气模式 发现”晴天→阴天→雨天→晴天”这个规律 基于这个模式预测明天可能是阴天 这就是RNN的”记忆”能力！ 2. RNN的数学原理2.1 前向传播公式RNN的前向传播可以用以下公式表示： ht=tanh⁡(Wxh⋅xt+Whh⋅ht−1+bh)h_t = \\tanh(W_{xh} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)ht​=tanh(Wxh​⋅xt​+Whh​⋅ht−1​+bh​) yt=Why⋅ht+byy_t = W_{hy} \\cdot h_t + b_yyt​=Why​⋅ht​+by​ 其中： xtx_txt​：当前时间步的输入 hth_tht​：当前时间步的隐藏状态 ht−1h_{t-1}ht−1​：上一个时间步的隐藏状态 yty_tyt​：当前时间步的输出 Wxh,Whh,WhyW_{xh}, W_{hh}, W_{hy}Wxh​,Whh​,Why​：权重矩阵 bh,byb_h, b_ybh​,by​：偏置项 2.2 隐藏状态的作用隐藏状态（Hidden State）是RNN的”记忆”所在： 信息存储：保存了从序列开始到当前时间步的所有重要信息 状态传递：将信息从一个时间步传递到下一个时间步 特征提取：自动学习序列中的重要特征和模式 numLayers示意图 图：多层RNN的结构示意图。展示了不同层数的RNN如何堆叠，每层都有自己的隐藏状态。 图片说明： 上标：不是指数，而是表示不同的层数 同色RNNCell：表示同一个RNN单元在不同时间步的重复使用 层间连接：展示了多层RNN中信息如何在不同层之间传递 要注意的是，在图中同样颜色的RNNCell是同一个，体现了RNN的参数共享特性。 3. 字符级RNN实现3.1 数据预处理在我们的实现中，我们使用了一个简单的字符级RNN来学习”hello”到”ohlol”的映射： 图：字符级RNN的任务示例。输入序列”hello”，输出序列”ohlol”。 如图，我们输入的序列即是’h’,’e’,’l’,’l’,’o’，将来隐层的输出就得是’o’,’h’,’l’,’o’,’l’。 我们遇到的问题就是，此时我们输入的是字符，而并不是一个向量，就会导致现在我们无法计算。 所以，我们第一步就需要把这些字符进行向量化，如下图所示： 图：字符向量化过程。从字符到索引，再到独热编码的转换过程。 字符向量化过程在自然语言处理中，我们需要将字符转换为神经网络能够处理的数值形式。这个过程分为几个步骤： 第一步：构建词典首先根据所有可能出现的字符构造一个词典，给每个字符分配一个唯一的索引。在我们的例子中： ‘e’ → 0 ‘h’ → 1 ‘l’ → 2 ‘o’ → 3 第二步：字符转索引根据词典，将输入序列中的每个字符转换为对应的索引： “hello” → [1, 0, 2, 2, 3] 第三步：索引转独热向量将每个索引转换为独热编码向量。独热向量的长度等于词典大小（本例中为4），只有一个位置为1，其余为0： 索引0 → [1, 0, 0, 0] 索引1 → [0, 1, 0, 0] 索引2 → [0, 0, 1, 0] 索引3 → [0, 0, 0, 1] 因此，input_size = 4（词典大小）。 输出处理输出格式RNN Cell的输出是一个长度为4的向量，表示对4个字符类别的预测概率分布。 损失计算 将RNN输出通过Softmax函数转换为概率分布 与真实标签（独热编码）计算交叉熵损失 使用CrossEntropyLoss进行训练 输出维度output_size = 4（对应4个字符类别） import torch input_size = 4 hidden_size = 4 batch_size = 1 idx2char = ['e', 'h', 'l', 'o'] # 字母列表 x_data = [1, 0, 2, 2, 3] # The input sequence is 'hello' y_data = [3, 1, 2, 3, 2] # The output sequence is 'ohlol' 3.2 模型定义class Model(torch.nn.Module): def __init__(self, input_size, hidden_size, batch_size): super(Model, self).__init__() self.batch_size = batch_size self.input_size = input_size self.hidden_size = hidden_size self.rnncell = torch.nn.RNNCell(input_size = self.input_size, hidden_size = self.hidden_size) def forward(self, input, hidden): hidden = self.rnncell(input, hidden) # h_t = cell(x_t, h_t-1) return hidden def init_hidden(self): #生成默认的初始h0 return torch.zeros(self.batch_size, self.hidden_size) 3.3 训练过程net = Model(input_size, hidden_size, batch_size) criterion = torch.nn.CrossEntropyLoss() # 交叉熵损失函数 optimizer = torch.optim.Adam(net.parameters(), lr = 0.1) # 优化器 for epoch in range(15): loss = 0 optimizer.zero_grad() # 优化器梯度归零 hidden = net.init_hidden() # 初始化hidden(算h0) print('Predicted string: ', end='') for input, label in zip(inputs, labels): # inputs: seq_len * batch_size * input_size hidden = net(input, hidden) # 核心语句,计算h_t loss += criterion(hidden, label) # 没有用item(),因为所有序列loss的和才是最终的loss _, idx = torch.max(hidden, dim = 1) print(idx2char[idx.item()], end='') loss.backward() optimizer.step() print(', epoch [%d/15] loss=%.4f' % (epoch + 1, loss.item())) 3.4 输出结果redicted string: hhhhh, epoch [1/15] loss=7.2311 Predicted string: ohlhh, epoch [2/15] loss=5.7348 Predicted string: ohlol, epoch [3/15] loss=4.5165 Predicted string: ohloh, epoch [4/15] loss=3.8056 Predicted string: ohloh, epoch [5/15] loss=3.4101 Predicted string: ohlol, epoch [6/15] loss=3.0576 Predicted string: ohlol, epoch [7/15] loss=2.7027 Predicted string: ohlol, epoch [8/15] loss=2.5969 Predicted string: ohlol, epoch [9/15] loss=2.5442 Predicted string: ohlol, epoch [10/15] loss=2.4160 Predicted string: ohlol, epoch [11/15] loss=2.2656 Predicted string: ohlol, epoch [12/15] loss=2.1754 Predicted string: ohlol, epoch [13/15] loss=2.1360 Predicted string: ohlol, epoch [14/15] loss=2.0996 Predicted string: ohlol, epoch [15/15] loss=2.0562 4. 代码详解4.1 参数设置input_size = 4表示输入特征的维度。由于我们的输入’hello’中有4个字母，所以input_size的值就是4。 hidden_size = 4是RNN隐藏状态的维度，也可以理解为”记忆单元”的数量。在我们这里将其设置为4，是为了让隐藏状态的维度和输入维度一致，便于理解和调试。 batch_size = 1表示每次输入RNN样本数量。这里设置为1，表示我们只输入了一个序列。 4.2 数据转换字母映射 idx2char = ['e', 'h', 'l', 'o'] # 字母列表 分别将字母’e’,’h’,’l’,’o’的索引设置为0，1，2，3。 序列转换我们输入的序列是’hello’，转换为张量就是[1, 0, 2, 2, 3]输出的序列是’ohlol’，转换为张量就是[3, 1, 2, 3, 2] 独热编码 one_hot_lookup = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]] x_one_hot = [one_hot_lookup[x] for x in x_data] one_hot_lookup 定义了一个”独热编码表”，每一行代表一个字母的 one-hot 编码。例如，第0行 [1, 0, 0, 0] 代表字母 ‘e’，第1行 [0, 1, 0, 0] 代表字母 ‘h’，以此类推。 x_one_hot = [one_hot_lookup[x] for x in x_data] 这行代码的作用是：把输入的索引序列 x_data（比如 [1, 0, 2, 2, 3]）转换成对应的 one-hot 向量序列。这样每个数字索引就变成了一个只有一个元素为1，其余为0的向量，方便神经网络处理。 通过这种方式，我们可以把原本用数字表示的字符序列，转化为神经网络能够直接处理的向量形式。每个 one-hot 向量都唯一对应一个字母，这样网络在训练时就能”看到”每个字母的独特身份，而不会混淆。独热编码是文本、分类等任务中常用的预处理方法，能够有效地将离散的类别信息转化为数值型输入，便于后续的模型学习和计算。 列表推导式语法x_one_hot = [one_hot_lookup[x] for x in x_data] 这句代码用的是”列表推导式”语法。它的作用是：遍历 x_data 里的每一个索引 x，然后用 x 去 one_hot_lookup 这个列表里查找对应的 one-hot 向量，把所有查到的 one-hot 向量依次组成一个新列表。这样，原本的 x_data（比如 [1, 0, 2, 2, 3]）就被转换成了一个 one-hot 编码的二维列表，每一行都是一个字母的 one-hot 表示。这样做的好处是可以让神经网络直接处理这些向量，而不是原始的数字索引。 所以说，x_one_hot其实就是一个二位列表，里面每一行都是一个字母的one-hot编码变量。 张量转换 inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size) 这句代码的作用如下： 首先，torch.Tensor(x_one_hot) 是把前面得到的 x_one_hot（一个二维列表）转换成 PyTorch 的张量（Tensor），这样才能被神经网络直接处理。 接着，.view(-1, batch_size, input_size) 是对这个张量进行形状调整（reshape）。 -1 表示这一维的长度自动推断（通常是序列长度 seq_len）。 batch_size 表示每次输入的样本数，这里是 1。 input_size 表示每个输入向量的长度，这里是 4。 最终，inputs 的形状就是 (seq_len, batch_size, input_size)，也就是”序列长度 × 批量大小 × 输入特征数”。这种格式正好是 PyTorch RNN 相关模块要求的输入格式。 所以说，这句代码就是把 one-hot 编码的输入数据，变成了神经网络能直接吃的张量，并且调整成了标准的 RNN 输入格式。 标签处理 labels = torch.LongTensor(y_data).view(-1, 1) 这句代码的作用如下： 首先，torch.LongTensor(y_data) 是把 y_data 这个标签序列（比如 [3, 1, 2, 3, 2]）转换成 PyTorch 的长整型张量（LongTensor），这是因为很多损失函数（比如 CrossEntropyLoss）要求标签必须是 long 类型。 接着，.view(-1, 1) 是对这个张量进行形状调整（reshape）。 -1 表示这一维的长度自动推断（通常是序列长度 seq_len）。 1 表示每个标签单独占一列。 最终，labels 的形状就是 (seq_len, 1)，也就是”序列长度 × 1”。这种格式正好适合和 RNN 输出的每一步结果一一对应。 所以说，这句代码就是把原始的标签序列变成了神经网络训练时能直接用的张量，并且调整成了和输入、输出一一对应的标准格式。 为什么用LongTensor？因为LongTensor用于标签，是因为标签必须是整数类型，如果是float类型就会报错。这是PyTorch的硬性规定，尤其是分类任务和交叉熵损失函数。 4.3 模型结构接下来，就是代码的核心部分，定义Model这个类，把RNNCell封装成了一个小模型。 在__init__方法中，我们会把传入的 input_size、hidden_size 和 batch_size 分别保存为成员变量，并且创建一个 RNNCell 实例进行初始化。 接着呢，定义了一个 forward 前馈方法，也就是模型每次接收到输入数据时，如何一步步计算输出的过程。在 forward 方法里，我们会先初始化一个隐藏状态（hidden），通常用全零向量开始。然后，遍历输入序列的每一个时间步，把当前的输入和上一个隐藏状态一起送进 RNNCell，得到新的隐藏状态。每一步的输出我们都会收集起来，最后把所有时间步的输出拼成一个整体，作为模型的最终输出返回。这样，forward 方法就完整地描述了 RNN 的前向传播流程。 至于init_hidden方法，则是用来生成默认的初始h_0的。 4.4 训练循环部分接着我们来看一下代码的主体循环部分： net = Model(input_size, hidden_size, batch_size) criterion = torch.nn.CrossEntropyLoss() # 交叉熵损失函数 optimizer = torch.optim.Adam(net.parameters(), lr = 0.1) # 优化器 for epoch in range(15): loss = 0 optimizer.zero_grad() # 优化器梯度归零 hidden = net.init_hidden() # 初始化hidden(算h0) print('Predicted string: ', end='') for input, label in zip(inputs, labels): # inputs: seq_len * batch_size * input_size hidden = net(input, hidden) # 核心语句,计算h_t loss += criterion(hidden, label) # 没有用item(),因为所有序列loss的和才是最终的loss _, idx = torch.max(hidden, dim = 1) print(idx2char[idx.item()], end='') loss.backward() optimizer.step() print(', epoch [%d/15] loss=%.4f' % (epoch + 1, loss.item())) 这段代码是整个训练过程的核心，我来详细解释一下每一步： 外层循环：训练轮次for epoch in range(15) 表示我们要训练15轮，每一轮都会用同样的数据来训练模型，让模型逐渐学会”hello”到”ohlol”的映射规律。 初始化阶段 loss = 0：每轮训练开始时，把损失值清零 optimizer.zero_grad()：把优化器里的梯度清零，这是必须的，因为PyTorch会累积梯度 hidden = net.init_hidden()：初始化隐藏状态，相当于给RNN一个”空白记忆” 内层循环：序列处理for input, label in zip(inputs, labels) 这行代码很有意思，它同时遍历输入序列和标签序列，每次取出一个输入字符和对应的目标字符。 核心计算 hidden = net(input, hidden)：这是最核心的一句！把当前输入和上一个隐藏状态送进RNN，得到新的隐藏状态 loss += criterion(hidden, label)：计算当前时间步的损失，并累加到总损失中 _, idx = torch.max(hidden, dim = 1)：从RNN的输出中找出概率最大的字符索引 print(idx2char[idx.item()], end='')：把索引转回字符并打印出来，这样我们就能看到模型预测的字符串 反向传播和更新 loss.backward()：计算梯度 optimizer.step()：用梯度更新模型参数 输出结果最后打印当前轮次和损失值，这样我们就能看到模型训练的进展。 这个训练过程其实就是在教RNN：看到’h’应该输出’o’，看到’e’应该输出’h’，以此类推。通过反复训练，RNN逐渐学会了这个映射规律。 4.5 优化器选择为什么这里用Adam优化器，而不用SGD优化器呢？ 这是一个很好的问题！其实两种优化器都可以用，但Adam在这个任务上有一些优势： Adam的优势 自适应学习率：Adam会根据每个参数的历史梯度自动调整学习率，对于不同参数使用不同的学习率，这样训练更稳定 收敛更快：通常Adam比SGD收敛得更快，特别是在这种小规模任务上 超参数少：我们只需要设置一个学习率（lr=0.1），而SGD可能需要调整学习率衰减等更多参数 SGD的特点 简单直接：SGD就是最基础的梯度下降，逻辑简单易懂 理论基础扎实：SGD的理论分析更成熟 在某些任务上表现更好：比如一些大规模数据集上，SGD可能泛化能力更强 为什么这里选Adam？因为我们的任务比较简单（只有4个字符的映射），数据量小，Adam的自适应特性能让训练过程更平滑，不容易出现震荡。而且我们不需要调太多超参数，直接用默认设置就能工作得很好。 当然，如果你把代码里的 torch.optim.Adam 改成 torch.optim.SGD，模型也能训练，只是可能需要调整学习率或者训练更多轮次。 总结 🎉本笔记系统介绍了循环神经网络的基本概念、数学原理和实现方法。通过天气预测的生动案例，帮助理解RNN的”记忆”机制；通过字符级RNN的完整实现，展示了RNN在序列数据处理中的应用。RNN作为深度学习中的重要模型，为自然语言处理、时间序列预测等任务提供了强大的工具。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"数据结构-绪论","slug":"数据结构-绪论","date":"2025-10-11T08:48:12.000Z","updated":"2025-10-13T02:08:40.249Z","comments":true,"path":"2025/10/11/数据结构-绪论/","permalink":"https://toddy110.github.io/2025/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BB%AA%E8%AE%BA/","excerpt":"1. 基本概念和术语数据 (Data)定义 | 数据 (Data): 数据是信息的载体, 是描述客观事物属性的数, 字符及所有能输入到计算机中并被计算机程序识别和处理的符号的集合. 对于计算机来说, 就是二进制的 0 和 1 数值型数据: 整数, 定点数, 浮点数非数值型数据: 文字数据","text":"1. 基本概念和术语数据 (Data)定义 | 数据 (Data): 数据是信息的载体, 是描述客观事物属性的数, 字符及所有能输入到计算机中并被计算机程序识别和处理的符号的集合. 对于计算机来说, 就是二进制的 0 和 1 数值型数据: 整数, 定点数, 浮点数非数值型数据: 文字数据 数据元素 (Data Element)定义 | 数据元素 (Data Element): 是数据的基本单位, 通常作为一个整体进行考虑和处理 (最小单位是 bit). 数据项 (Data Item)定义 | 数据项 (Data Item): 一个数据元素可由若干数据项组成, 数据项是构成数据元素的不可分割的最小单位. 我们要根据实际的业务需求来确定什么是数据元素, 什么是数据项 数据元素又称为元素, 结点, 记录 (record) 数据结构 (Data Structure)结构: 各个元素之间的关系 (relationships among elements) 数据结构 (Data Structure): 形式定义: 某一数据对象的所有数据成员之间的关系. 记为:Data_Structure={D,S} \\text{Data\\_Structure} = \\{ D, S \\} Data_Structure={D,S} 其中, D 是某一数据对象, S 是该对象中所有数据成员之间的关系的有限集合. 例: 复数的数据结构定义 (complex number) 数据对象 (Data Object)数据对象 (Data Object): 具有相同性质的数据元素的集合, 是数据的一个子集 整数数据对象 N={0,±1,±2,… }N = \\{0,\\pm1, \\pm2, \\dots\\}N={0,±1,±2,…} 字符数据对象 C={′A′,′B′,′C′,⋯ ,′F′}C = \\{'A','B','C',\\cdots, 'F'\\}C={′A′,′B′,′C′,⋯,′F′} 俱乐部会员表数据对象 (club member table) 数据处理 (Data Processing)数据处理 (Data Processing): 将数据通过人力或机器, 将收集到的数据加以系统的处理, 归纳出有价值的信息 排序, 归并, 编辑, 计算, 查找, 查询, 分类, 变换等 数据结构 (Data Structure) 的三要素 (Three Elements)(1) 逻辑结构 (Logical Structure) — 数据结构之间的逻辑关系是什么 从逻辑关系上描述数据, 与数据的存储无关; 从具体问题抽象出来的数据模型 (data model) 与数据元素本身的形式, 内容无关 数据的逻辑结构分类 线性结构: 线性表, 栈 (stack), 队列 (queue), 数组 (array), 串 (string) 非线性结构: 树 (tree), 图 (graph 或 network), 广义表, 多维数组 四个基本结构:集合 (Set): 各个元素同属一个集合, 别无其他关系 线性结构 (Linear): 数据元素之间是一对一的关系. 除了第一个元素, 所有元素都有唯一前驱; 除了最后一个元素, 所有元素都有唯一后继 树形结构 (Tree): 数据元素之间是一对多的关系 网状结构 (Graph): 数据元素之间是多对多的关系 (2) 物理结构 (Physical Structure) — 如何用计算机表示数据元素的逻辑关系顺序存储 (Sequential Storage): 把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中, 元素之间的关系由存储单元的邻接关系来体现 链式存储 (Linked Storage): 逻辑上相邻的元素在物理位置上可以不相邻, 借助指示元素存储地址的指针来表示元素之间的逻辑关系 索引存储 (Indexed Storage): 在存储元素信息的同时, 还建立附加的索引表. 索引表中的每项称为索引项, 索引项的一般形式是 (关键字, 地址) 散列存储 (Hash Storage): 根据元素的关键字直接计算出该元素的存储地址, 又称哈希 (Hash) 存储 若采用顺序存储, 则各个数据元素在物理上必须是连续的; 若采用非顺序存储, 则各个元素在物理上可以是离散的 数据的存储结构会影响存储空间分配的方便程度 数据的存储结构会影响对数据运算的速度 存储方式 逻辑相邻是否物理相邻 额外信息 优点 缺点 顺序存储 (Sequential) 是 无 随机访问快 插入/删除慢 链式存储 (Linked) 否 指针/引用 插入/删除快 额外指针开销 索引存储 (Indexed) 否 索引表 查找加速 维护索引成本 散列存储 (Hash) 否 哈希函数 访问接近 O(1) 冲突与退化 (3) 数据的运算 (Operations) — 施加在数据上的运算包括运算的定义和实现运算的定义是针对逻辑结构的, 运算的实现是针对存储结构的, 指出运算的具体操作步骤 抽象数据类型 (Abstract Data Type, ADT)数据类型 (Data Type): 一个值的集合和定义在这个值集上的一组操作的总称 C 语言中的基本数据类型: int (整型), char (字符型), float (浮点型), double (双精度型), void (无值) 抽象数据类型 (Abstract Data Type, ADT): 是指一个数学模型以及定义在此数学模型上的一组操作 逻辑特性, 与在计算机内的表示与实现无关抽象数据类型 === 数据结构 +++ 定义在此数据结构上的一组操作 矩阵的抽象数据类型: 矩阵 + (求转置, 加, 乘, 求逆, 求特征值) //complex.h //隐藏数据表示，不提供具体的说明 typedef struct complex *Complex; Complex COMPLEXinit(float , float); float Re(Complex); float Im(Complex); Complex COMPLEXmult(Complex, Complex); Complex COMPLEXadd(Complex, Complex); void showComplex(Complex ); 抽象数据类型的描述: 抽象数据类型可用(D,P,S)三元组表示 D是数据对象 S是D上的关系集 P是对D的基本操作集 ADT 抽象数据类型名 { 数据对象：〈数据对象的定义〉 数据关系：〈数据关系的定义〉 基本操作：〈基本操作的定义〉 } ADT 抽象数据类型名 数据对象,数据关系用伪码描述;基本操作定义格式为: 基本操作名（参数表） 初始条件：〈初始条件描述〉 操作结果：〈操作结果描述〉 基本操作有两种参数:赋值参数只为操作提供输入值;引用参数以&amp;打头,除可提供输入值外,还将返回操作结果 “初始条件”描述了操作执行之前数据结构和参数应满足的条件,若不满足,则操作失败,并返回相应出错信息 “操作结果”说明了操作正常完成之后,数据结构的变化状况和应返回的结果. 抽象数据类型的表示和实现:抽象数据类型可以通过固有数据类型（高级编程语言中已实现的数据类型）来实现： 抽象数据类型 数据对象 基本操作 类 class 数据成员 成员函数（方法） 在C++中,类的成分(数据成员和成员函数)可以有三种访问级别: private 私有成分(只允许类的成员函数进行访问) protected 保护成分(只允许类的成员函数及其子孙类进行访问) public 公有成分(允许类的成员函数,类的实例及其子孙类,子孙类的实例进行访问) 2. 程序的产生五个阶段: 需求(输入,输出) 设计(编写算法) 分析(选择最佳算法) 细化与编码(编写程序) 验证(程序验证、测试、调试) 算法分析算法定义为了解决某类问题而规定的一个有限长的操作序列 特性 有穷性:算法在执行有穷步后能结束 确定性:每步定义都是确切,无歧义 可行性:每一条运算应足够基本 输入:有0个或多个输入 输出:有一个或多个输出 算法设计例子:选择排序 (Selection Sort)问题:递增排序解决方案:逐个选择最小数据代码如下: void SelectSort(int a[], int n) { for (int i = 0; i &lt; n - 1; i++) { int k = i; // 从a[i]查到a[n-1], 找最小整数, 在a[k] for (int j = i + 1; j &lt; n; j++) { if (a[i] &lt; a[j]) { k = j; a[i] ^= a[j]; a[j] ^= a[i]; a[i] ^= a[j];// 邪修,用来交换数值 } } } } 性能分析与度量评价标准算法的评价标准: 正确性:包括不含语法错误,对几组数据运行正确,对典型,苛刻的数据运行正确,对所有数据运行正确 可读性: 效率:高效,低存储需要.(算法执行时间短,同时所占用的存储空间小) 健壮性:当输入非法数据时,算法也能作出适当反应,而不会出现莫名其妙的输出结果 时间复杂度 (Time Complexity)后期测试(实测)算法的后期测试:在算法中的某些部位插装时间函数time(),测定算法完成某一功能所花费时间 double start, stop; time (&amp;start); int k = seqsearch (a, n, x); time (&amp;stop); double runTime = stop - start; printf (\" %d%d\\n \" , n, runTime); 事前估计(分析)算法的事前估计: 运行时间 = 算法中每条语句执行时间之和 每条语句执行时间 = 该语句的执行次数(频度)* 语句执行一次所需时间 语句执行一次所需时间取决于机器的指令性能和速度和编译所产生的代码质量,很难确定 设每条语句执行一次所需时间为单位时间,则一个算法的运行时间就是该算法中所有语句的频度之和 定义与表示法时间复杂度:算法中语句重复执行次数的数量级是时间复杂度.表示方法: T(n)=O(f(n)) T(n) = O(f(n)) T(n)=O(f(n)) T(n)T(n)T(n)称做渐进时间复杂度,简称时间复杂度 f(n)f(n)f(n)表示基本操作重复执行的次数,是nnn的某个函数,随问题规模nnn的增大,算法执行时间的增长率和f(n)f(n)f(n)的增长率属于同一数量级 OOO表示f(n)f(n)f(n)和T(n)T(n)T(n)只相差一个常数倍 示例 1:常数时间打印(O(1))下面看两个代码.代码一: void print(int a[]) { int i = 0; cout &lt;&lt; a[i]; i++; cout &lt;&lt; a[i]; } 结论:时间复杂度为O(1)O(1)O(1) 示例 2:线性时间打印(O(n))代码二: void print (int a[], int n) { int i = 0; for(i = 0;i &lt; n; i++) cout &lt;&lt; a[i]; } 结论:时间复杂度为O(n)O(n)O(n) 示例 3:顺序查找 (Sequential Search, 平均复杂度 O(n))再来看一个代码: int seqsearch(int a[], int n, int x) { // 在a[0],...,a[n - 1]中搜索x int i = 0; while(i &lt; n &amp;&amp; a[i] != x) i++; if(i == n) return -1; return i; } 平均操作次数为(1+2+3+⋯+n+n)∗1n+1=n(n+3)2(n+1)(1 + 2 + 3 + \\cdots + n + n) * \\frac{1}{n+1} = \\frac{n(n+3)}{2(n+1)}(1+2+3+⋯+n+n)∗n+11​=2(n+1)n(n+3)​, 时间复杂度为O(n)O(n)O(n) 空间复杂度 (Space Complexity) 存储空间的固定部分:程序指令代码的空间,常数,简单变量,定长成分(如数组元素,结构成分,对象的数据成员等)变量所占空间 可变部分:尺寸与实例特性有关的成分变量所占空间,引用变量所占空间,递归栈所用空间,通过new和delete命令动态使用空间 几种时间复杂度 O(1)O(1)O(1):常数时间 O(log2n)O(log_{2}{n})O(log2​n):对数时间 O(n)O(n)O(n):线性时间 O(nlog2n)O(nlog_{2}{n})O(nlog2​n):线性对数时间 O(n2)O(n^2)O(n2):平方时间 O(n3)O(n^3)O(n3):立方时间 O(2n)O(2^n)O(2n):指数时间 上述的时间复杂度的优劣次序如下(n≥16)(n \\geq 16)(n≥16): O(1)&lt;O(log2n)&lt;O(n)&lt;O(nlog2n)&lt;O(n2)&lt;O(n3)&lt;O(2n) O(1)&lt;O(log_{2}{n})&lt;O(n)&lt;O(nlog_{2}{n})&lt;O(n^2)&lt;O(n^3)&lt;O(2^n) O(1)&lt;O(log2​n)&lt;O(n)&lt;O(nlog2​n)&lt;O(n2)&lt;O(n3)&lt;O(2n) 重要知识点: 算法的计算量的大小称为计算的复杂性 链接存储表示中数据元素之间的逻辑关系是由指针表示的 算法的时间复杂度取决于问题的规模和待处理数据的状态 在数据结构中，与所使用的计算机无关的是数据的逻辑结构 数据元素是数据的基本单位，而不是最小单位 ;最小单位是bit 数据的不可分割的最小单位是数据项","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://toddy110.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://toddy110.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"author":"ModestyN"},{"title":"CNN基础","slug":"CNN基础","date":"2025-10-01T04:50:12.000Z","updated":"2025-10-12T05:40:14.001Z","comments":true,"path":"2025/10/01/CNN基础/","permalink":"https://toddy110.github.io/2025/10/01/CNN%E5%9F%BA%E7%A1%80/","excerpt":"","text":"CNN (Convolutional Neural Network, 卷积神经网络) (基础) 1. 图像基础与本质1.1 图像的输入结构以MNIST数据集为例, 灰度图像的输入尺寸为 1×28×281 \\times 28 \\times 281×28×28, 即: 通道数 (Channel): 1, 表示灰度图像只有一个颜色通道; 宽度 (Width): 28, 图像的宽度为28像素; 高度 (Height): 28, 图像的高度为28像素. 在实际应用中, 彩色图像通常包含红 (R), 绿 (G), 蓝 (B) 三个通道 (channel). 1.2 数字图像的本质数字图像 (digital image) 本质上是由像素 (Pixel) 组成的二维矩阵, 每个像素记录了对应位置的光强或颜色信息. 在数字成像系统 (digital imaging system) 中, 常用光敏电阻 (Photoresistor) 或光电二极管 (Photodiode) 作为感光元件. 光敏电阻的电阻值会随着光照强度的变化而变化. 通过在电路中测量光敏电阻两端的电压和电流, 可以计算出其电阻值, 进而推算出该位置的光强. 成像时, 通常会使用透镜系统将外部光线聚焦到感光元件阵列上. 每个光敏电阻对应一个光锥, 接收器尺寸越小, 光锥角度越小, 能够采集的空间分辨率越高. 多个光敏电阻按照规则排布, 形成感光阵列, 每个光敏电阻即为一个像素. 整个阵列即可采集一幅完整的图像. 彩色图像通常在每个像素位置上设置多个不同颜色滤光片 (如红, 绿, 蓝), 分别采集不同波段的光强, 实现彩色成像. 在实际的彩色数字成像设备中, 最常见的滤色片排列方式是拜耳阵列 (Bayer Pattern), 其中最常见的是RGGB排列. RGGB表示每2×2的像素块中有2个绿色, 1个红色和1个蓝色滤光片, 排列如下: 红 (R) 绿 (G) 绿 (G) 蓝 (B) 这种设计是因为人眼对绿色更敏感, 因此绿色像素数量更多. 通过拜耳阵列采集到的原始数据, 经过插值算法 (去马赛克, Demosaicing) 后, 可以还原出全分辨率的彩色图像. 因此, 数字图像的本质是对空间中光强分布的离散采样和数字化表达. 分辨率越高, 能够还原的细节越丰富. 1.3 栅格图像与矢量图像 栅格图像 (Raster Image): 由像素 (Pixel) 组成的二维矩阵, 每个像素有固定的颜色或灰度值. 常见格式有JPEG, PNG, BMP等. 优点是能够表现丰富的细节和复杂的色彩变化, 适合照片, 扫描图像等. 缺点是放大后会出现锯齿 (失真), 文件体积较大. 矢量图像 (Vector Image): 由点, 线, 曲线和多边形等几何图形通过数学公式描述. 常见格式有SVG, EPS, PDF等. 优点是无论放大多少倍都不会失真, 文件体积通常较小, 适合图标, 标志, 插画等. 缺点是不适合表现复杂的色彩渐变和细节丰富的照片. 应用场景: 栅格图像常用于数码摄影, 医学影像, 遥感等需要表现真实世界细节的场合. 矢量图像常用于平面设计, 排版, CAD制图等需要高精度缩放和清晰边界的场合. 2. 卷积操作与特征提取2.1 卷积操作的基本原理在进行卷积操作时, 通常会在图像上选取一个小块 (patch), 其形状为 3×H′×W′3 \\times H' \\times W'3×H′×W′, 其中3表示输入的通道数 (如RGB三通道), H′H'H′ 和 W′W'W′ 分别为该块的高度和宽度. 这个小块会作为卷积核的感受野, 在整张图像上以滑动窗口的方式移动, 遍历所有位置. 每次滑动时, 对当前区域进行卷积计算, 得到一个输出值. 所有位置的输出值拼接在一起, 形成新的特征图 (feature map). 卷积操作完成后, 输出的通道数, 宽度和高度通常会发生变化. 每个输出通道 (output channel) 都综合了输入patch中的全部信息, 代表了不同的特征响应. 2.2 卷积层的结构与流程 图像首先经过卷积层 (convolutional layer), 如 5×55 \\times 55×5 卷积核, 可以得到4个通道, 每个通道 24×2424 \\times 2424×24 的特征图 (feature map, 记作 C1C_1C1​). 卷积层的作用是提取图像的空间特征. 卷积操作后, 输出张量依然保持三维结构 (通道数 × 宽度 × 高度), 但通道数, 宽度和高度可能发生变化. 与全连接层 (fully connected layer) 不同, 全连接层会将图像展平成一维向量, 丧失原有的空间结构信息. 卷积层输出的特征图通常会经过下采样 (subsampling/pooling), 如 2×22 \\times 22×2 池化, 得到新的特征图 (S1S_1S1​), 例如4个通道, 每个通道 12×1212 \\times 1212×12. 下采样操作会减小宽度和高度, 通道数保持不变, 主要目的是减少数据量, 降低计算复杂度. 可以继续堆叠卷积层和下采样层. 例如, 再经过一个 5×55 \\times 55×5 卷积, 得到 C2C_2C2​ (8个通道, 8×88 \\times 88×8), 再下采样一次, 得到 S2S_2S2​ (8个通道, 4×44 \\times 44×4). 最后,将三阶张量(如 8×4×48 \\times 4 \\times 48×4×4)展平成一维向量(通过 view 操作),再通过全连接层映射到十维输出,完成分类任务.常用交叉熵损失(cross-entropy loss)和 softmax 进行概率分布计算. 总结:构建神经网络时,需要明确输入和输出张量的维度,并通过不同的层结构将其映射到目标空间,实现特征提取与分类(Feature Extraction + Classification). 3. 卷积操作的数学与代码示例3.1 单通道卷积计算过程以 5×55 \\times 55×5 的输入矩阵和 3×33 \\times 33×3 的卷积核为例,演示卷积操作的计算过程: 输入(Input): 3 4 6 5 7 2 4 6 8 2 1 6 7 8 4 9 7 4 6 2 3 7 5 4 1 卷积核(Kernel): 1 2 3 4 5 6 7 8 9 输出(Output): 211 295 262 259 282 214 251 253 169 详细计算过程: 左上角输出(第1行第1列): 3×1+4×2+6×3+2×4+4×5+6×6+1×7+6×8+7×9=2113\\times1 + 4\\times2 + 6\\times3 + 2\\times4 + 4\\times5 + 6\\times6 + 1\\times7 + 6\\times8 + 7\\times9 = 2113×1+4×2+6×3+2×4+4×5+6×6+1×7+6×8+7×9=211 第1行第2列: 4×1+6×2+5×3+4×4+6×5+8×6+6×7+7×8+8×9=2954\\times1 + 6\\times2 + 5\\times3 + 4\\times4 + 6\\times5 + 8\\times6 + 6\\times7 + 7\\times8 + 8\\times9 = 2954×1+6×2+5×3+4×4+6×5+8×6+6×7+7×8+8×9=295 第1行第3列: 6×1+5×2+7×3+6×4+8×5+2×6+7×7+8×8+4×9=2626\\times1 + 5\\times2 + 7\\times3 + 6\\times4 + 8\\times5 + 2\\times6 + 7\\times7 + 8\\times8 + 4\\times9 = 2626×1+5×2+7×3+6×4+8×5+2×6+7×7+8×8+4×9=262 第2行第1列: 2×1+4×2+6×3+1×4+6×5+7×6+9×7+7×8+4×9=2592\\times1 + 4\\times2 + 6\\times3 + 1\\times4 + 6\\times5 + 7\\times6 + 9\\times7 + 7\\times8 + 4\\times9 = 2592×1+4×2+6×3+1×4+6×5+7×6+9×7+7×8+4×9=259 第2行第2列: 4×1+6×2+8×3+6×4+7×5+8×6+7×7+4×8+6×9=2824\\times1 + 6\\times2 + 8\\times3 + 6\\times4 + 7\\times5 + 8\\times6 + 7\\times7 + 4\\times8 + 6\\times9 = 2824×1+6×2+8×3+6×4+7×5+8×6+7×7+4×8+6×9=282 第2行第3列: 6×1+8×2+2×3+7×4+8×5+4×6+4×7+6×8+2×9=2146\\times1 + 8\\times2 + 2\\times3 + 7\\times4 + 8\\times5 + 4\\times6 + 4\\times7 + 6\\times8 + 2\\times9 = 2146×1+8×2+2×3+7×4+8×5+4×6+4×7+6×8+2×9=214 第3行第1列: 1×1+6×2+7×3+9×4+7×5+4×6+3×7+7×8+5×9=2511\\times1 + 6\\times2 + 7\\times3 + 9\\times4 + 7\\times5 + 4\\times6 + 3\\times7 + 7\\times8 + 5\\times9 = 2511×1+6×2+7×3+9×4+7×5+4×6+3×7+7×8+5×9=251 第3行第2列: 6×1+7×2+8×3+7×4+4×5+6×6+7×7+5×8+4×9=2536\\times1 + 7\\times2 + 8\\times3 + 7\\times4 + 4\\times5 + 6\\times6 + 7\\times7 + 5\\times8 + 4\\times9 = 2536×1+7×2+8×3+7×4+4×5+6×6+7×7+5×8+4×9=253 第3行第3列: 7×1+8×2+4×3+4×4+6×5+2×6+5×7+4×8+1×9=1697\\times1 + 8\\times2 + 4\\times3 + 4\\times4 + 6\\times5 + 2\\times6 + 5\\times7 + 4\\times8 + 1\\times9 = 1697×1+8×2+4×3+4×4+6×5+2×6+5×7+4×8+1×9=169 注:每个输出值对应卷积核在输入矩阵上滑动到不同位置时,patch与kernel对应元素相乘后求和的结果. 3.2 多通道卷积的结构与参数在卷积神经网络中,多通道卷积的本质是:每个输出通道都通过对所有输入通道分别进行卷积,再将结果按元素相加得到. 更为严谨地说,假设输入特征图的通道数为 CinC_{in}Cin​,输出特征图的通道数为 CoutC_{out}Cout​,卷积核的空间尺寸为 Kh×KwK_h \\times K_wKh​×Kw​.那么,卷积核的权重张量形状为: (out_channels, in_channels, kernel_size_h, kernel_size_w) 其中,kernel_size_h 和 kernel_size_w 分别表示卷积核的高度和宽度. 具体计算流程如下: 每个输出通道的生成 对于每一个输出通道 o (o=1,2,…,C_out),都对应有 C_in 个二维卷积核(每个输入通道一个). 对于每个输入通道 i (i=1,2,…,C_in),用该通道的输入特征图与对应的卷积核进行二维卷积,得到一个中间特征图. 将所有 C_in 个中间特征图按元素相加(逐元素求和),得到该输出通道的最终特征图. 卷积核权重的组织 整个卷积层的权重是一个四维张量,形状为 (out_channels, in_channels, kernel_size_h, kernel_size_w). 其中,第 o 个输出通道的卷积核权重为 W[o, :, :, :],包含了对所有输入通道的卷积核. 输出张量的形状 假设输入张量形状为 (N, C_in, H_in, W_in),其中 N 是批量大小. 输出张量的形状为 (N, C_out, H_out, W_out),其中 H_out 和 W_out 由输入尺寸,卷积核尺寸,步幅,填充等参数共同决定. 举例说明 以常见的 RGB 图像为例,C_in=3.若设置 C_out=16,则该卷积层共有 16×3=48 个二维卷积核,每个输出通道都融合了所有输入通道的信息. 总结: 每个输出通道都聚合了所有输入通道的卷积结果. 卷积核的四维结构确保了输入通道和输出通道之间的全连接. 这种设计使得网络能够学习到跨通道的复杂特征组合. 因此,PyTorch 等深度学习框架中,Conv2d 层的权重参数形状为 (out_channels, in_channels, kernel_size_h, kernel_size_w),严格对应上述数学描述. 3.3 代码示例:多通道卷积由此,我们可以写出卷积操作的示例代码: import torch in_channels, out_channels = 5, 10 width, height = 100, 100 kernel_size = 3 batch_size = 1 input = torch.randn(batch_size, in_channels, width, height) conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size) output = conv_layer(input) print(input.shape) print(output.shape) print(conv_layer.weight.shape) 下面对上述代码中的各个参数和操作进行有条理的说明: 输入输出通道数 in_channels:表示输入张量的通道数.例如,对于RGB彩色图像,in_channels=3;对于灰度图像,in_channels=1.本例中设为5,表示输入有5个通道. out_channels:表示卷积操作后输出张量的通道数.这个值由我们自行设定,通常越大,网络能够学习到的特征越丰富.本例中设为10. 图像尺寸 width 和 height:分别表示输入图像的宽度和高度.本例中均为100. 卷积核大小 kernel_size:指定卷积核的空间尺寸.可以是单个整数(表示正方形卷积核),也可以是二元组(如(3, 5),表示非正方形卷积核).本例中为3,表示 3×33 \\times 33×3 的卷积核. 输入张量的生成 input = torch.randn(batch_size, in_channels, width, height):生成一个形状为 (batch_size, in_channels, width, height) 的四维张量,元素服从标准正态分布.这里 batch_size=1,表示一次只输入一张多通道图像. 卷积层的定义 conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size):创建一个二维卷积层.需要指定输入通道数,输出通道数和卷积核大小这三个核心参数. 注意:卷积核的形状不一定要是正方形(即width=height),但实际应用中常用正方形卷积核(如 3×33 \\times 33×3,5×55 \\times 55×5 等),因为其在空间上具有对称性,便于特征提取. 通过上述参数的设定,可以灵活地构建适用于不同输入数据和任务需求的卷积层结构. 输出结果如下: torch.Size([1, 5, 100, 100]) torch.Size([1, 10, 98, 98]) torch.Size([10, 5, 3, 3]) 4. 卷积操作的参数详解4.1 Padding(填充)Padding(填充)用于在输入特征图的边缘补零,以控制输出特征图的空间尺寸. 公式: padding = (kernel_size - 1) / 2 其中 kernel_size 是卷积核的尺寸(如 3,5,7 等).如果卷积核尺寸为奇数,这个公式可以保证输出尺寸与输入尺寸一致. 代码示例:Paddingimport torch input = [3, 4, 6, 5, 7, 2, 4, 6, 8, 2, 1, 6, 7, 8, 4, 9, 7, 4, 6, 2, 3, 7, 5, 4, 1] input = torch.Tensor(input).view(1, 1, 5, 5) conv_layer = torch.nn.Conv2d(1, 1, kernel_size = 3, padding = 1) kernel = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).view(1, 1, 3, 3) conv_layer.weight.data = kernel.data output = conv_layer(input) print(output) 上述代码演示了如何在 PyTorch 中手动设置输入,卷积核,并使用 padding 进行卷积操作. 首先,定义了一个 5×55 \\times 55×5 的输入矩阵,并用 torch.Tensor(...).view(1, 1, 5, 5) 变成四维张量,符合卷积层的输入格式(batch size, channel, height, width). 创建了一个 3×33 \\times 33×3 的卷积核,并手动赋值给卷积层的权重. padding=1 表示在输入的每一边都补上一圈0,使得输出的空间尺寸与输入一致. 最后,将输入送入卷积层,输出结果的空间尺寸仍为 5×55 \\times 55×5,验证了 padding 的作用. 通过这个例子可以直观理解 padding 如何影响卷积输出的尺寸. 输出结果如下: tensor([[[[ 90.9643, 167.9643, 223.9643, 214.9643, 126.9643], [113.9643, 210.9643, 294.9643, 261.9643, 148.9643], [191.9643, 258.9643, 281.9643, 213.9643, 121.9643], [193.9643, 250.9643, 252.9643, 168.9643, 85.9643], [ 95.9643, 111.9643, 109.9643, 67.9643, 30.9643]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 4.2 Stride(步幅)Stride(步幅)用于控制卷积核在输入特征图上每次移动的距离. stride=2 表示卷积核每次在输入特征图上移动2个像素(而不是默认的1个像素). 这样会导致输出特征图的宽度和高度都变小,相当于对输入做了下采样. 通过设置不同的stride,可以灵活控制输出特征图的空间尺寸. 本例中,输入为 5×55 \\times 55×5,卷积核为 3×33 \\times 33×3,stride=2,输出的空间尺寸会比stride=1时更小. 代码示例:Strideimport torch input = [3, 4, 6, 5, 7, 2, 4, 6, 8, 2, 1, 6, 7, 8, 4, 9, 7, 4, 6, 2, 3, 7, 5, 4, 1] input = torch.Tensor(input).view(1, 1, 5, 5) conv_layer = torch.nn.Conv2d(1, 1, kernel_size = 3, stride = 2, bias = False) kernel = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).view(1, 1, 3, 3) conv_layer.weight.data = kernel.data output = conv_layer(input) print(output) 上述代码演示了stride(步幅)参数的作用: stride=2 表示卷积核每次在输入特征图上移动2个像素. 这样会导致输出特征图的宽度和高度都变小,相当于对输入做了下采样. 通过设置不同的stride,可以灵活控制输出特征图的空间尺寸. 本例中,输入为 5×55 \\times 55×5,卷积核为 3×33 \\times 33×3,stride=2,输出的空间尺寸会比stride=1时更小. 通过这个例子可以直观理解stride对卷积输出尺寸的影响. 输出结果如下: tensor([[[[211., 262.], [251., 169.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 5. 下采样(Pooling)操作5.1 MaxPooling(最大池化)MaxPooling(最大池化)是一种常用的下采样方法.对于 2×22 \\times 2 2×2 的MaxPooling,默认stride = 2. 其原理是在每个 2×22 \\times 22×2 区域内取最大值,减小特征图尺寸,通道数保持不变. Maxpooling只能在一个通道内做,通道之间是无法做Maxpooling的(通道数量不变,图像大小变化). 代码示例:MaxPoolingimport torch input = [3, 4, 6, 5, 2, 4, 6, 8, 1, 6, 7, 8, 9, 7, 4, 6] input = torch.Tensor(input).view(1, 1, 4, 4) maxpooling_layer = torch.nn.MaxPool2d(kernel_size = 2) output = maxpooling_layer(input) print(output) 该代码的核心是torch.nn.MaxPool2d,并设置kernel_size = 2,这样同样也默认了步长stride = 2. 输出结果如下: tensor([[[[4., 8.], [9., 8.]]]]) 6. CNN网络结构流程举例 输入:(batch, 1, 28, 28) Conv2d Layer 1: filter 5×55 \\times 55×5, CinC_{in}Cin​:1, CoutC_{out}Cout​:10 → (batch, 10, 24, 24) Pooling Layer 1: filter 2×22 \\times 22×2 → (batch, 10, 12, 12) Conv2d Layer 2: filter 5×55 \\times 55×5, CinC_{in}Cin​:10, CoutC_{out}Cout​:20 → (batch, 20, 8, 8) Pooling Layer 2: filter 2×22 \\times 22×2 → (batch, 20, 4, 4) 展平成向量,经过全连接层映射为10类输出. 最终代码实现: import torch from torchvision import transforms, datasets from torch.utils.data import DataLoader import torch.nn.functional as F import torch.optim as optim batch_size = 64 transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) train_dataset = datasets.MNIST( root='D:/PythonCode/Pytorch_learning/MNIST', train=True, download=True, transform=transform ) train_loader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True ) test_dataset = datasets.MNIST( root='D:/PythonCode/Pytorch_learning/MNIST', train=False, download=True, transform=transform ) test_loader = DataLoader( test_dataset, batch_size=batch_size, shuffle=False ) class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5) self.pooling = torch.nn.MaxPool2d(2) self.fc = torch.nn.Linear(320, 10) def forward(self, x): batch_size = x.size(0) x = F.relu(self.pooling(self.conv1(x))) x = F.relu(self.pooling(self.conv2(x))) x = x.view(batch_size, -1) x = self.fc(x) return x model = Net() criterion = torch.nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) def train(epoch): running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0 def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: inputs, labels = data outputs = model(inputs) _, predicted = torch.max(outputs.data, dim = 1) total += labels.size(0) correct += (predicted == labels).sum().item() print('Accuracy on test set: %d %% [%d/%d]' % (100 * correct / total, correct, total)) if __name__ == '__main__': for epoch in range(10): train(epoch) test() 本笔记系统梳理了卷积神经网络的输入结构,卷积与池化操作的原理,参数设置,数学推导与代码实现,并通过具体的网络结构流程示例,帮助理解CNN的整体信息流与特征提取机制.","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"author":"Modesty"}],"categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构","slug":"数据结构","permalink":"https://toddy110.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://toddy110.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构","slug":"数据结构","permalink":"https://toddy110.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]}